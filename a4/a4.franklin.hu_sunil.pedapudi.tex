\documentclass{article}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{fullpage}
\begin{document}
Franklin Hu, Sunil Pedapudi \\
CS 194-10 Machine Learning \\
Fall 2011 \\
Assignment 4 \\

\begin{enumerate}
    \item Linear neural networks % 1
        \begin{enumerate}
            \item % 1a
                Suppose we have a three layer neural network with one input
                layer \(x\), one hidden layer \(h\), and one output layer 
                \(y\). Each layer can be expressed as a vector of the 
                values of the nodes in that layer. For example,
                \begin{equation*}
                    \bf{y}= \left( \begin{array}{c}
                    y_1 \\
                    y_2 \\
                    \vdots \\
                    y_n \end{array} \right)
                \end{equation*}
                Assume that each neural node has its own set of weights 
                \(\bf{w_i}\) where \(i\) is the node index. We can express 
                the value of a particular output in terms of the hidden 
                layer
                \begin{equation*}
                    y_k= g(\bf{h})
                \end{equation*}
                Since we are only considering linear activation functions,
                we can write this equation in terms of a constant
                multiplied by the weighted sum of inputs
                \begin{equation*}
                    y_k= c_{y_k} \cdot \bf{w_{y_k}} \cdot \bf{h}
                \end{equation*}
                where \(c_{y_k}\) is the constant multiplier of \(y_k\),
                \(w_{y_k}\) is the set of weights for \(y_k\), and \(h\)
                is the vector of hidden nodes. \\
                Similarly, we can express the value of each node in the 
                hidden layer in terms of the inputs.
                \begin{equation*}
                    h_j= c_{h_j} \cdot \bf{w_{h_j}} \cdot \bf{x}
                \end{equation*}
                Now, we can see that the output layer nodes can simply be 
                written in terms of the inputs without the hidden layer.
                For a particular output node:
                \begin{align*}
                    y_k
                        &= c_{y_k} \cdot \bf{w_{y_k}} \cdot \bf{h} \\
                        &= c_{y_k} \cdot \bf{w_{y_k}} \cdot
                            \left( \begin{array}{c}
                            h_1 \\
                            h_2 \\
                            \vdots \\
                            h_n 
                            \end{array} \right) \\
                        &= c_{y_k} \cdot \bf{w_{y_k}} \cdot 
                            \left( \begin{array}{c}
                            {c_h}_1 \cdot \bf{w_{h_1}} \cdot \bf{x} \\
                            {c_h}_2 \cdot \bf{w_{h_2}} \cdot \bf{x} \\
                            \vdots \\
                            {c_h}_n \cdot \bf{w_{h_n}} \cdot \bf{x}
                            \end{array} \right) \\
                        &= c_{y_k} \cdot (\bf{w_{y_k}} \cdot \bf{c_h} \cdot
                            I \cdot \bf{w_h}) \cdot \bf{x}
                \end{align*}
                where \(c_h\) is a vector of the constant weight for each
                hidden node, \(I\) is the identity matrix, and \(w_h\) is
                a matrix of the weight vectors of the hidden nodes.
                Thus we can define a new weight vector \(\bf{u_{y_k}}\) for
                the output node \(y_k\)
                \begin{equation*}
                    {\bf{u_{y_k}}}= \bf{w_{y_k}} \cdot \bf{c_h} \cdot \bf{I}
                    \cdot \bf{w_h}
                \end{equation*}
                We can thus simply compute the value of \(y_k\) in terms of
                \(x\).
            \item % 1b
                For an arbitrary number of hidden nodes, the same
                computation can be done. Suppose we have \(h\) hidden layers
                with \(\bf{h_1}\) having \(\bf{x}\) as inputs and \(\bf{y}\)
                having \(\bf{h_n}\) as inputs. In this case, consider the 
                sub-network of \(\bf{h_2}\), \(\bf{h_1}\), and \(\bf{x}\). 
                Using the technique in part (a), we can write the expression
                for \(\bf{h_2}\) in terms only of \(\bf{x}\).  The resulting
                expression
                \begin{equation*}
                    {\bf{{h_2}_i}}= c_{h_2} \cdot \bf{u_{h_2}} \cdot \bf{x}
                \end{equation*}
                still has a linear activation function and therefore this
                technique generalizes to the remaining hidden nodes. We
                repeat this process for all the hidden nodes and can thus
                write the expression for any output node \(y_k\)
                \begin{equation*}
                    y_k= c_{y_k} \cdot \bf{w_{y_k}} \cdot \left( 
                         \prod\limits_{i=1}^h \bf{c_{h_i}} \cdot \bf{I} 
                         \cdot \bf{w_{h_i}} \right) \cdot \bf{x}
                \end{equation*}
            \item % 1c
                For the case when \(h \ll n\), a neural net with the hidden
                layer will do \(O(hn)\) computations to find the linear
                combination of the weighted sum of inputs whereas without
                the hidden layer, as shown in (a), the output is only
                dependent on \(x\). This computations is \(O(n)\), so we 
                save those \(h-1\) other computations over the inputs.
        \end{enumerate}
    \item ML estimation of exponential model \\ % 2
        Knowing
        \begin{equation*}
            P(x) = \frac{1}{b}e^{-\frac{x}{b}}
        \end{equation*}
        \begin{enumerate}
            \item % 2a
                We write the likelihood function given \(x_i\) as
                \begin{align*}
                \mathcal{L}(b) 
                &= \prod_{i = 1}^N \frac{1}{b}e^{-\frac{x_i}{b}}\\
                &= \left(\frac{1}{b}\right)^N \prod_{i=1}^N e^{-\frac{x_i}{b}}\\
                &= \left(\frac{1}{b}\right)^N e^{\sum_{i=0}^N -\frac{x_i}{b}}\\
                &= \left(\frac{1}{b}\right)^N exp(-\frac{1}{b}\sum_{i=0}^N x_i)\\
                \textnormal{Let } \bar{x} &= \frac{1}{N}\sum_{i=1}^Nx_i,\\
                \mathcal{L}(b) &= \left(\frac{1}{b}\right)^N exp(-\frac{1}{b}N\bar{x})
                \end{align*}

            \item %pp 2b
                We first find
                \begin{align*}
                log(\mathcal{L}) 
                    &= log\left(\left(\frac{1}{b}\right)^N exp(-\frac{1}{b}N\bar{x})\right)\\
                    &= log\left(\frac{1}{b}\right)^N + 
                        log\left(e^{-\frac{1}{b}N\bar{x}}\right)\\
                    &= N(log(1) - log(b)) -\frac{1}{b}N\bar{x}\\
                    &= -Nlog(b) - \frac{1}{b}N\bar{x}
                \end{align*}

                Then, let \(\theta = \frac{1}{b}\), the parameter variable
                \begin{align*}
                    \frac{\partial log(\mathcal{L}(\theta))}{\partial \theta}
                    &= \frac{\partial Nlog(\theta)}{\partial \theta} - 
                    \frac{\partial \theta N\bar{x}}{\partial \theta}\\
                    &= \frac{N}{\theta} - \frac{\partial \theta N\bar{x}}{\partial \theta}\\
                    &= \frac{N}{\theta} - N\bar{x}\\
                    &= Nb - N\bar{x}
                \end{align*}

            \item % 2c
                We aim to maximize \(\mathcal{L}\) so,
                \begin{equation*}
                    \frac{\partial \mathcal{L}}{\partial \theta} = 
                    Nb - N\bar{x} = 0
                \end{equation*}
                We can solve this to find 
                \begin{equation*}
                  b = \bar{x} = \frac{1}{N}\sum_{i=0}^Nx_i
                \end{equation*}
        \end{enumerate}

    \item ML estimation of noisy-OR model % 3
    
    \item Naive Bayes models for spam filtering % 4
        \begin{enumerate}
            \item % 4a
            \item % 4b
                We modified the skeleton code in NBmodel.py. We were not
                sure what the point was to have each NaiveBayesModel have
                a pointer to another model and just made this base class the
                model used. Most of the training and classification code was
                common between the Boolean and NTF subclasses with the
                exception of the classification code to calculate the log
                probabilities. \\
            \item % 4c
                If classifying ham as spam is \(c\) times worse than 
                classifying spam and ham and the model returns a
                probability p that the message is spam, we can simply
                calculate the expected value given that probability. \\
                If the cost ratio is \(c\), we assign the following values:
                \begin{align*}
                    \text{Value}(Y=\text{SPAM}|\hat{Y}=\text{SPAM}) &= +1 \\
                    \text{Value}(Y=\text{HAM}|\hat{Y}=\text{HAM}) &= +1 \\
                    \text{Value}(Y=\text{SPAM}|\hat{Y}=\text{HAM}) &= -c \\
                    \text{Value}(Y=\text{HAM}|\hat{Y}=\text{SPAM}) &= -1
                \end{align*}
                For correctly classifying an example, we give it value 
                \(+1\). For incorrectly classifying spam as ham, assign
                value \(-1\), and for incorrectly classifying ham as spam,
                we give it the cost ratio value \(-c\). \\
                For example, if classifying ham as spam is twice as bad
                as classifying spam as ham, \(c=2\). \\
                When the model returns a probability \(p\) that the example
                is spam, we do the following:
                \begin{itemize}
                    \item
                        If \(p>0.5\), we would normally classify this
                        example as spam.
                        \begin{align*}
                            \mathbb{E}[\text{Value}] 
                            &= \text{Value}(Y=\text{SPAM}|\hat{Y}=
                                \text{SPAM}) \cdot p +
                                \text{Value}(Y=\text{HAM}|\hat{Y}=
                                \text{SPAM}) \cdot (1 - p) \\
                            &= 1 \cdot p - c \cdot (1 - p) \\
                            &= p - c + cp
                        \end{align*}
                        If the expected value is positive, then we go ahead
                        and classify the item as SPAM, and otherwise HAM.
                    \item
                        If \(p<0.5\), we would normally classify this
                        example as ham.
                        \begin{align*}
                            \mathbb{E}[\text{Value}] 
                            &= \text{Value}(Y=\text{HAM}|\hat{Y}=
                                \text{HAM}) \cdot (1 - p) +
                                \text{Value}(Y=\text{SPAM}|\hat{Y}=
                                \text{HAM}) \cdot p \\
                            &= 1 \cdot (1 - p) - 1 \cdot p \\
                            &= 1 - p - p \\
                            &= 1 - 2p
                        \end{align*}
                        Since \(p<0.5\), this expected value is always
                        positive, so we always classify HAM if the model
                        says to.
                    \item
                        If \(p=0.5\), then we just look at the cost ratio.
                        If the cost ratio is more than 1, we classify it as
                        SPAM; if less than 1, HAM; and if equal to 1, we
                        flip a fair coin.
                \end{itemize}
            \item % 4d
                In general, we calcuate the log probability ratio:
                \begin{equation*}
                    \frac{P(Y=1|X)}{P(Y=0|X)} \rightarrow
                    \text{log}\frac{P(Y=1|X)}{P(Y=0|X)} 
                \end{equation*}
                If the original ratio is greater than 1, then we classify
                the example as spam. If it is less than 1, we classify it 
                as ham. If it is equal to one, we flip a fair coin. \\
                When we take the log, we simply adjust the value we compare
                it to since \(log1=0\). \\
                For Boolean features, our expression for the likelihood is
                \begin{align*}
                    P(Y=1|X)
                        &= P(Y=1) \cdot P(X|Y=1) \\
                        &= P(Y=1) \cdot \prod\limits_{i=1}^n P(x_i|Y=1) \\
                        &= \alpha \theta_1 \prod\limits_{i=1}^n 
                            {\theta_{1i}}^{x_i}(1-\theta_{1i})^{1-x_i}
                \end{align*}
                Since we assume that the attributes are independent, we can
                turn \(P(X|Y=1)\) into a product of the individual
                probabilities. \\
                When we take the log ratio, we get
                \begin{align*}
                    \frac{P(Y=1|X)}{P(Y=0|X)}
                        &= \frac
                            {\alpha \theta_1 
                                \prod\limits_{i=1}^n {\theta_{1i}}^{x_i}
                                (1-\theta_{1i})^{1-x_i}}
                            {\alpha \theta_0
                                \prod\limits_{i=1}^n {\theta_{0i}}^{x_i}
                                (1-\theta_{0i})^{1-x_i}} \\
                        &= \frac
                            {\theta_1 
                                \prod\limits_{i=1}^n {\theta_{1i}}^{x_i}
                                (1-\theta_{1i})^{1-x_i}}
                            {\theta_0
                                \prod\limits_{i=1}^n {\theta_{0i}}^{x_i}
                                (1-\theta_{0i})^{1-x_i}} \\
                    \text{log} \frac{P(Y=1|X)}{P(Y=0|X)}
                        &= \text{log} \left( \theta_1 
                                \prod\limits_{i=1}^n {\theta_{1i}}^{x_i}
                                (1-\theta_{1i})^{1-x_i} \right) -
                           \text{log} \left( \theta_0
                                \prod\limits_{i=1}^n {\theta_{0i}}^{x_i}
                                (1-\theta_{0i})^{1-x_i} \right) \\
                        &= \text{log}\theta_1 - \text{log}\theta_0 + 
                                \sum\limits_{i=1}^n 
                                    x_i \cdot \text{log}\theta_{1i} + 
                                    (1-x_i) \cdot \text{log}(1-\theta_{1i})
                                    -
                                \sum\limits_{i=1}^n 
                                    x_i \cdot \text{log}\theta_{0i} -
                                    (1-x_i) \cdot \text{log}(1-\theta_{0i})
                \end{align*}
                For NTF, we can make the same independence assumption and
                derive a log probability ratio
                \begin{align*}
                    \frac{P(Y=1|X)}{P(Y=0|X)}
                    &= \frac{P(Y=1) \cdot P(X|Y=1)}{P(Y=0) \cdot P(X|Y=0)}
                        \\
                    &= \frac
                        {P(Y=1) \cdot \prod\limits_{i=1}^n P(x_i|Y=1)}
                        {P(Y=0) \cdot \prod\limits_{i=1}^n P(x_i|Y=0)} \\
                    &= \frac
                        {\alpha \theta_1 \prod\limits_{i=1}^n
                            \frac{1}{b_i} e^{-\frac{x_i}{b_i}}}
                        {\alpha \theta_0 \prod\limits_{j=1}^n
                            \frac{1}{b_j} e^{-\frac{x_j}{b_j}}} \\
                    &= \frac
                        {\theta_1 \prod\limits_{i=1}^n
                            \frac{1}{b_i} e^{-\frac{x_i}{b_i}}}
                        {\theta_0 \prod\limits_{j=1}^n
                            \frac{1}{b_j} e^{-\frac{x_i}{b_j}}} \\
                    \text{log} \frac{P(Y=1|X)}{P(Y=0|X)}
                    &= \text{log} \frac
                        {\theta_1 \prod\limits_{i=1}^n
                            \frac{1}{b_i} e^{-\frac{x_i}{b_i}}}
                        {\theta_0 \prod\limits_{j=1}^n
                            \frac{1}{b_j} e^{-\frac{x_i}{b_j}}} \\
                    &= \text{log} \left( \theta_1 \prod\limits_{i=1}^n
                            \frac{1}{b_i} e^{-\frac{x_i}{b_i}} \right) -
                        \text{log} \left( \theta_0 \prod\limits_{j=1}^n
                            \frac{1}{b_j} e^{-\frac{x_i}{b_j}} \right) \\
                    &= \text{log} \theta_1 - \text{log} \theta_0 +
                        \sum\limits_{i=1}^n \text{log} \left( \frac{1}{b_i} 
                            e^{-\frac{x_i}{b_i}} \right) -
                        \sum\limits_{j=1}^n \text{log} \left( \frac{1}{b_j}
                            e^{-\frac{x_i}{b_j}} \right) \\
                    &=  \text{log} \theta_1 - \text{log} \theta_0 +
                        \left( \sum\limits_{i=1}^n -\text{log} b_i - 
                            \frac{x_i}{b_i} \right)
                         - \left( \sum\limits_{j=1}^n - \text{log} b_j - 
                            \frac{x_j}{b_j} \right)
                \end{align*}
                where \(b_i\) and \(b_j\) are the appropriate constants
                calucated with the closed form solution in question 2 for
                each feature.
            \item % 4e
              We discuss two of the feature selection heuristics that were 
              considered. First, we considered a \(\chi^2\) metric as
              \begin{equation*}
                \chi^2 = \sum_{i=1}^n \left(\frac{(n_{iSPAM} 
                  - \mu_{iSPAM})^2}{\mu_{iSPAM}} +
                \frac{(n_{iHAM} 
                  - \mu_{iHAM})^2}{\mu_{iHAM}}\right)
              \end{equation*}
              Essentially, this is a metric comparing the class to a feature,
              and we wished to show that if, for a given feature, 
              \(\chi^2 > 3.84\), we can claim that with 95\% confidence, this
              feature is strongly associated with spam or ham without 
              coincidence. \\
              Another approach considered was to utilize a simplified 
              information gain as
              \begin{equation*}
                I_{gain} = -\sum_{i=0}^n FREQ_{spam}(i)log(FREQ_{spam}(i)) +
                FREQ_{ham}(i)log(FREQ_{ham}(i))
              \end{equation*}
              For its simplicity, we used this metric of information gain where
              we aimed to identify features that are strongly associated with
              spam or ham. For its simplicity, we utilized this metric. 
        \end{enumerate}
\end{enumerate}

\end{document}
